[{"content":"Abstract In recent years, significant progress has been made in the medical image analysis domain using convolutional neural networks (CNNs). In particular, deep neural networks based on a U-shaped architecture (UNet) with skip connections have been adopted for several medical imaging tasks, including organ segmentation. Despite their great success, CNNs are not good at learning global or semantic features. Especially ones that require human-like reasoning to understand the context. Many UNet architectures attempted to adjust with the introduction of Transformer-based self-attention mechanisms, and notable gains in performance have been noted. However, the transformers are inherently flawed with redundancy to learn at shallow layers, which often leads to an increase in the computation of attention from the nearby pixels offering limited information. The recently introduced Super Token Attention (STA) mechanism adapts the concept of superpixels from pixel space to token space, using super tokens as compact visual representations. This approach tackles the redundancy by learning efficient global representations in vision transformers, especially for the shallow layers. In this work, we introduce the STA module in the UNet architecture (STA-UNet), to limit redundancy without losing rich information. Experimental results on four publicly available datasets demonstrate the superiority of STA-UNet over existing state-of-the-art architectures in terms of Dice score and IOU for organ segmentation tasks.\nCollaborators Mayo Clinic, Phoenix AZ School of Computing, Clemson University Medical Imaging and Data Science (MINDS) Lab, Washington University in St. Louis ðŸ”— Paper Pre-print\nðŸ”— Code\n","permalink":"http://localhost:1313/blog/sta-unet/","summary":"\u003ch2 id=\"abstract\"\u003eAbstract\u003c/h2\u003e\n\u003cp\u003eIn recent years, significant progress has been made in the medical image analysis domain using convolutional neural networks (CNNs). In particular, deep neural networks based on a U-shaped architecture (UNet) with skip connections have been adopted for several medical imaging tasks, including organ segmentation. Despite their great success, CNNs are not good at learning global or semantic features. Especially ones that require human-like reasoning to understand the context. Many UNet architectures attempted to adjust with the introduction of Transformer-based self-attention mechanisms, and notable gains in performance have been noted. However, the transformers are inherently flawed with redundancy to learn at shallow layers, which often leads to an increase in the computation of attention from the nearby pixels offering limited information. The recently introduced Super Token Attention (STA) mechanism adapts the concept of superpixels from pixel space to token space, using super tokens as compact visual representations. This approach tackles the redundancy by learning efficient global representations in vision transformers, especially for the shallow layers. In this work, we introduce the STA module in the UNet architecture (STA-UNet), to limit redundancy without losing rich information. Experimental results on four publicly available datasets demonstrate the superiority of STA-UNet over existing state-of-the-art architectures in terms of Dice score and IOU for organ segmentation tasks.\u003c/p\u003e","title":"STA-Unet: Rethink the semantic redundant for Medical Imaging Segmentation"},{"content":"Abstract Retinal fundus photography offers a non-invasive way to diagnose and monitor a variety of retinal diseases, but is prone to inherent quality glitches arising from systemic imperfections or operator/patient-related factors. However, high-quality retinal images are crucial for carrying out accurate diagnoses and automated analyses. The fundus image enhancement is typically formulated as a distribution alignment problem, by finding a one-to-one mapping between a low-quality image and its high-quality counterpart. This paper proposes a context-informed optimal transport (OT) learning framework for tackling unpaired fundus image enhancement. In contrast to standard generative image enhancement methods, which struggle with handling contextual information (e.g., over-tampered local structures and unwanted artifacts), the proposed context-aware OT learning paradigm better preserves local structures and minimizes unwanted artifacts. Leveraging deep contextual features, we derive the proposed context-aware OT using the earth mover\u0026rsquo;s distance and show that the proposed context-OT has a solid theoretical guarantee. Experimental results on a large-scale dataset demonstrate the superiority of the proposed method over several state-of-the-art supervised and unsupervised methods in terms of signal-to-noise ratio, structural similarity index, as well as two downstream tasks.\nCollaborators Mayo Clinic, Phoenix AZ Medical Imaging and Data Science (MINDS) Lab, Washington University in St. Louis ðŸ”— Paper Pre-print\nðŸ”— Code\n","permalink":"http://localhost:1313/blog/context-ot/","summary":"\u003ch2 id=\"abstract\"\u003eAbstract\u003c/h2\u003e\n\u003cp\u003eRetinal fundus photography offers a non-invasive way to diagnose and monitor a variety of retinal diseases, but is prone to inherent quality glitches arising from systemic imperfections or operator/patient-related factors. However, high-quality retinal images are crucial for carrying out accurate diagnoses and automated analyses. The fundus image enhancement is typically formulated as a distribution alignment problem, by finding a one-to-one mapping between a low-quality image and its high-quality counterpart. This paper proposes a context-informed optimal transport (OT) learning framework for tackling unpaired fundus image enhancement. In contrast to standard generative image enhancement methods, which struggle with handling contextual information (e.g., over-tampered local structures and unwanted artifacts), the proposed context-aware OT learning paradigm better preserves local structures and minimizes unwanted artifacts. Leveraging deep contextual features, we derive the proposed context-aware OT using the earth mover\u0026rsquo;s distance and show that the proposed context-OT has a solid theoretical guarantee. Experimental results on a large-scale dataset demonstrate the superiority of the proposed method over several state-of-the-art supervised and unsupervised methods in terms of signal-to-noise ratio, structural similarity index, as well as two downstream tasks.\u003c/p\u003e","title":"Context-Aware Optimal Transport Learning for Retinal Fundus Image Enhancement"},{"content":"Abstract Retinal fundus photography is significant in diagnosing and monitoring retinal diseases. However, systemic imperfections and operator/patient-related factors can hinder the acquisition of high-quality retinal images. Previous efforts in retinal image enhancement primarily relied on GANs, which are limited by the trade-off between training stability and output diversity. In contrast, the SchrÃ¶dinger Bridge (SB), offers a more stable solution by utilizing Optimal Transport (OT) theory to model a stochastic differential equation (SDE) between two arbitrary distributions. This allows SB to effectively transform low-quality retinal images into their high-quality counterparts. In this work, we leverage the SB framework to propose an image-to-image translation pipeline for retinal image enhancement. Additionally, previous methods often fail to capture fine structural details, such as blood vessels. To address this, we enhance our pipeline by introducing Dynamic Snake Convolution, whose tortuous receptive field can better preserve tubular structures. We name the resulting retinal fundus image enhancement framework the Context-aware Unpaired Neural SchrÃ¶dinger Bridge (CUNSB-RFIE). To the best of our knowledge, this is the first endeavor to use the SB approach for retinal image enhancement. Experimental results on a large-scale dataset demonstrate the advantage of the proposed method compared to several state-of-the-art supervised and unsupervised methods in terms of image quality and performance on downstream tasks.\nCollaborators Mayo Clinic, Phoenix AZ School of Computing, Clemson University Medical Imaging and Data Science (MINDS) Lab, Washington University in St. Louis ðŸ”— Paper Pre-print\nðŸ”— Code\n","permalink":"http://localhost:1313/blog/cunsb-rfie/","summary":"\u003ch2 id=\"abstract\"\u003eAbstract\u003c/h2\u003e\n\u003cp\u003eRetinal fundus photography is significant in diagnosing and monitoring retinal diseases. However, systemic imperfections and operator/patient-related factors can hinder the acquisition of high-quality retinal images. Previous efforts in retinal image enhancement primarily relied on GANs, which are limited by the trade-off between training stability and output diversity. In contrast, the SchrÃ¶dinger Bridge (SB), offers a more stable solution by utilizing Optimal Transport (OT) theory to model a stochastic differential equation (SDE) between two arbitrary distributions. This allows SB to effectively transform low-quality retinal images into their high-quality counterparts. In this work, we leverage the SB framework to propose an image-to-image translation pipeline for retinal image enhancement. Additionally, previous methods often fail to capture fine structural details, such as blood vessels. To address this, we enhance our pipeline by introducing Dynamic Snake Convolution, whose tortuous receptive field can better preserve tubular structures. We name the resulting retinal fundus image enhancement framework the Context-aware Unpaired Neural SchrÃ¶dinger Bridge (CUNSB-RFIE). To the best of our knowledge, this is the first endeavor to use the SB approach for retinal image enhancement. Experimental results on a large-scale dataset demonstrate the advantage of the proposed method compared to several state-of-the-art supervised and unsupervised methods in terms of image quality and performance on downstream tasks.\u003c/p\u003e","title":"CUNSB-RFIE: Context-aware Unpaired Neural SchrÃ¶dinger Bridge in Retinal Fundus Image Enhancement"},{"content":"Abstract Age progression is a process of projection of futuristic aging characteristics onto the subject face image. This kind of task finds applications in cyber-cell forensics, age-invariant facial recognition, and in entertainment sectors up to a certain extent. Most of the previous works tried projecting similar kinds of texture-based artifacts such as artificial wrinkles and dullness of eyes on the test subjects. Even, the analysis to convince the aging effects, as well as identity preservation in the generated images, is not studied in a detailed manner. In this work, we for the first time used the Attention mechanism in combination with weighted contextual loss to accomplish age progression of the human face. We used Attention UNet Generator architecture with the pyramid architecture of discriminator to aid the realness of the generated images. We have also shown the ablation studies for generators with differ- ent blocks in encoder and decoder. By using weighted Contextual loss, we induced the aging artifacts onto the test subject without losing the original identity. We have shown how perceptually close the results are to the real images. Performance evaluation of our work is carried out with the help of external age estimation and identity matching agents for better convincing and reliable quantitative analysis. Our method is robust to occlusion and some regular positions of the faces. This work is done under the guidance and collaboration of the premier R\u0026amp;D organization Center for Development of Advanced Computing (C-DAC), Hyderabad.\nThis work is completed as Part-2 of my Master\u0026rsquo;s Thesis at IIT Gandhinagar under the supervision of Dr. Shanmuganathan Raman and Mr. Ganga Prasad Rajuladevi.\nCollaborators Center for Development of Advanced Computing (C-DAC), Hyderabad, India. ðŸ”— Thesis Report\nðŸ”— Code\n","permalink":"http://localhost:1313/blog/faceagepro/","summary":"\u003ch2 id=\"abstract\"\u003eAbstract\u003c/h2\u003e\n\u003cp\u003eAge progression is a process of projection of futuristic aging characteristics\nonto the subject face image. This kind of task finds applications in cyber-cell\nforensics, age-invariant facial recognition, and in entertainment sectors up to\na certain extent. Most of the previous works tried projecting similar kinds\nof texture-based artifacts such as artificial wrinkles and dullness of eyes on\nthe test subjects. Even, the analysis to convince the aging effects, as well\nas identity preservation in the generated images, is not studied in a detailed\nmanner. In this work, we for the first time used the Attention mechanism in\ncombination with weighted contextual loss to accomplish age progression of\nthe human face. We used Attention UNet Generator architecture with the\npyramid architecture of discriminator to aid the realness of the generated\nimages. We have also shown the ablation studies for generators with differ-\nent blocks in encoder and decoder. By using weighted Contextual loss, we\ninduced the aging artifacts onto the test subject without losing the original\nidentity. We have shown how perceptually close the results are to the real\nimages. Performance evaluation of our work is carried out with the help of\nexternal age estimation and identity matching agents for better convincing\nand reliable quantitative analysis. Our method is robust to occlusion and\nsome regular positions of the faces. This work is done under the guidance\nand collaboration of the premier R\u0026amp;D organization Center for Development\nof Advanced Computing (C-DAC), Hyderabad.\u003c/p\u003e","title":"Mapping Human face age progression using Contextual loss"},{"content":"Abstract The Human Digestive System plays a crucial role in the nutrition supple- ment of the human body. Monitoring the digestive tract for deformations such as polyps can result in the prevention of fatalities like colo-rectal can- cer. Gastro-intestinal tract endoscopy is a prime diagnosis technique for the detection of such deformations. Diagnosis from images can be automated using the recent advancements in deep learning and AI. Apart from detec- tion, the exact segmentation of polyps can further aid the information to decide the extent of deformation and prescribe the course of treatment. It would also help the automated treatment systems for dissection of the polyp region. Image segmentation has been addressed using different techniques including CNNs and loss functions. But less emphasis was made on utiliz- ing Generative Adversarial Networks in Medical Image segmentation tasks. In our approach, we formulated Polyp Segmentation as an Image-to-image translation task using conditional GANs. We conducted a rigorous experi- mental study to prove that our approach delivers better efficiency in terms of qualitative and quantitative results. We experimented with different combi- nations of Generator architectures, GAN training schemes, and loss functions and showed the comparative study. We used standard datasets for training our experimental setup and proving the generality of our approach.\nThis work is completed as Part-1 of my Master\u0026rsquo;s Thesis at IIT Gandhinagar under the supervision of Dr. Shanmuganathan Raman.\nðŸ”— Thesis Report\n","permalink":"http://localhost:1313/blog/polypseg/","summary":"\u003ch2 id=\"abstract\"\u003eAbstract\u003c/h2\u003e\n\u003cp\u003eThe Human Digestive System plays a crucial role in the nutrition supple-\nment of the human body. Monitoring the digestive tract for deformations\nsuch as polyps can result in the prevention of fatalities like colo-rectal can-\ncer. Gastro-intestinal tract endoscopy is a prime diagnosis technique for the\ndetection of such deformations. Diagnosis from images can be automated\nusing the recent advancements in deep learning and AI. Apart from detec-\ntion, the exact segmentation of polyps can further aid the information to\ndecide the extent of deformation and prescribe the course of treatment. It\nwould also help the automated treatment systems for dissection of the polyp\nregion. Image segmentation has been addressed using different techniques\nincluding CNNs and loss functions. But less emphasis was made on utiliz-\ning Generative Adversarial Networks in Medical Image segmentation tasks.\nIn our approach, we formulated Polyp Segmentation as an Image-to-image\ntranslation task using conditional GANs. We conducted a rigorous experi-\nmental study to prove that our approach delivers better efficiency in terms of\nqualitative and quantitative results. We experimented with different combi-\nnations of Generator architectures, GAN training schemes, and loss functions\nand showed the comparative study. We used standard datasets for training\nour experimental setup and proving the generality of our approach.\u003c/p\u003e","title":"Polyp Segmentation in Gastro Intestinal Tract Endoscopy using Image to Image translation"},{"content":"Summary This project is a part of my ongoing thesis work, where we are trying to mimic the behaviour of multiple machines in the multi-staged assembly line production. Say there are 5 machines across 3 different stages of the production and are interdependent on each other functionalities and feedback received. There is huge neccessity to forecast the state of machines given any arbitrary configuration of input static variables (such as material composition, fabrication type and lot sequence). This would help the production unit to analyze the power consumption, identifying the idle machines and decide on the utilities. Although the traditional agent/component based simulators are in place for the specific factory setups, they are prone to certain limitations. These simulators are highly computing reliant and comsume lot of computational power and time. As these simulators mimic the process step by step as per the production instructions, given a huge lot size, they take up lot of time to provide the stats and sometimes lead to crashing the hosts. We aim to replace these agents with the help of latest advancements in Machine learning base Time-series analytics.\nDescription We leveraged the Temporal Fusion Transformers (TFT) to accomplish the task. We aimed to forecast the idle time profiles given the Lot configurations as static input features. We curated the data (idle/active profiles) by simulating the Model using DEVS simulator for all the Machines in the intial stage of the production. We used the 3:1 ratio to split the generated sequences for Training and Testing purposes. Then we leveraged TFT model to learn these time series profiles and later on testing this on unseen data. The same is illustrated well in the below figure.\nWe used keras and tensorflow based python implementation to accomplish this. Our performance is quantified using the confusion matrix, and specialized metrics for the binary time series forecasting. In future, we will be aiming to extrapolate this work to forecast the profiles for all the machines in the entire simulation.\nWe are in the process of developing the Github repo for this work. Meanwhile, you can refer to the discussed TFT model from this paper.\n","permalink":"http://localhost:1313/projects/idle-time/","summary":"\u003ch2 id=\"summary\"\u003eSummary\u003c/h2\u003e\n\u003cp\u003eThis project is a part of my ongoing thesis work, where we are trying to mimic the behaviour of multiple machines in the multi-staged assembly line production. Say there are 5 machines across 3 different stages of the production and are interdependent on each other functionalities and feedback received. There is huge neccessity to forecast the state of machines given any arbitrary configuration of input static variables (such as material composition, fabrication type and lot sequence). This would help the production unit to analyze the power consumption, identifying the idle machines and decide on the utilities. Although the traditional agent/component based simulators are in place for the specific factory setups, they are prone to certain limitations. These simulators are highly computing reliant and comsume lot of computational power and time. As these simulators mimic the process step by step as per the production instructions, given a huge lot size, they take up lot of time to provide the stats and sometimes lead to crashing the hosts. We aim to replace these agents with the help of latest advancements in Machine learning base Time-series analytics.\u003c/p\u003e","title":"Machine State prediction using the Temporal Fusion Transformers for Semicoductor fabrication"},{"content":"ðŸ”— Github Summary In this project, I built an elastic application that can automatically scale out and in on-demand and cost-effectively by using the PaaS cloud. Specifically, I built this application using AWS Lambda and other supporting services from AWS. AWS Lambda is the first and currently the most widely used function-based serverless computing service. This application demonstrates a meaningful cloud service to users, and the technologies and techniques that learned will be useful to develop more complex cloud based applications.\nDescription This complete cloud app is a video analysis application that uses four Lambda functions to implement a multi-stage pipeline to process videos sent by users.\nThe pipeline starts with a user uploading a video to the input bucket. Stage 1: The video-splitting function splits the video into frames and chunks them into the group-of-pictures (GoP) using FFmpeg. It stores this group of pictures in an intermediate stage-1 bucket. Stage 2: The face-recognition function extracts the faces in the pictures using a Single Shot MultiBox Detector (SSD) algorithm and uses only the frames that have faces in them for face recognition. It uses a pre-trained CNN model (ResNet-34) for face recognition and outputs the name of the extracted face. The final output is stored in the output bucket. The architecture of the cloud application is shown below. We will use AWS Lambda to implement the functions and AWS S3 to store the data required for the functions. The running instructions are clearly explained in the github readme file.\n","permalink":"http://localhost:1313/projects/cloud-app/","summary":"\u003ch3 id=\"-githubhttpsgithubcomvasavamsiaws-elastic-application-for-facial-recognitiontreemain\"\u003eðŸ”— \u003ca href=\"https://github.com/vasavamsi/AWS-Elastic-Application-for-facial-recognition/tree/main\"\u003eGithub\u003c/a\u003e\u003c/h3\u003e\n\u003ch2 id=\"summary\"\u003eSummary\u003c/h2\u003e\n\u003cp\u003eIn this project, I built an elastic application that can automatically scale out and in on-demand and cost-effectively by using the PaaS cloud. Specifically, I built this application using AWS Lambda and other supporting services from AWS. AWS Lambda is the first and currently the most widely used function-based serverless computing service. This application demonstrates a meaningful cloud service to users, and the technologies and techniques that learned will be useful to develop more complex cloud based applications.\u003c/p\u003e","title":"AWS Elastic Application for facial recognition"},{"content":"ðŸ”— Github Summary This project is a Python implementation to Train ResNet18 architecture on MINIJSRT dataset for Direction classification and Gender classification tasks. It also includes the pre-trained weights and Grad-CAM implementation (activation Heatmap generation).\nDataset Download Direction classification and Gender classfication dataset from MINIJSRT database. follow this link to accomplish the same. Split the dataset into train, validation and test sets.\nGrad-CAM implementation Gradient-weighted Class Activation Mapping (Grad-CAM) is a technique used in deep learning to visualize and understand the regions of an input image that a model focuses on when making predictions. It\u0026rsquo;s particularly useful for convolutional neural networks (CNNs) in tasks like image classification. Grad-CAM generates a heatmap that highlights the important regions contributing to the model\u0026rsquo;s decision.\nKey Features:\nClass-specific: Grad-CAM can generate heatmaps for specific classes, helping to interpret what the model learns for each class. Backpropagation: It uses gradients flowing into the final convolutional layer to produce the heatmap. Direction classification results are shown below:\nGender classification results are shown below:\n","permalink":"http://localhost:1313/projects/x-ray-classification/","summary":"\u003ch3 id=\"-githubhttpsgithubcomvasavamsipytorch-implementation-of-resnet18-with-grad-cam-on-mininjsrt-dataset-for-classification-task\"\u003eðŸ”— \u003ca href=\"https://github.com/vasavamsi/Pytorch-implementation-of-ResNet18-with-Grad-CAM-on-MININJSRT-dataset-for-classification-task\"\u003eGithub\u003c/a\u003e\u003c/h3\u003e\n\u003ch2 id=\"summary\"\u003eSummary\u003c/h2\u003e\n\u003cp\u003eThis project is a Python implementation to Train ResNet18 architecture on MINIJSRT dataset for Direction classification and Gender classification tasks. It also includes the pre-trained weights and Grad-CAM implementation (activation Heatmap generation).\u003c/p\u003e\n\u003ch2 id=\"dataset\"\u003eDataset\u003c/h2\u003e\n\u003cp\u003eDownload Direction classification and Gender classfication dataset from MINIJSRT database. follow this \u003ca href=\"http://imgcom.jsrt.or.jp/minijsrtdb/\" style=\"color: orange;\"\u003elink\u003c/a\u003e to accomplish the same. Split the dataset into train, validation and test sets.\u003c/p\u003e\n\u003ch2 id=\"grad-cam-implementation\"\u003eGrad-CAM implementation\u003c/h2\u003e\n\u003cp\u003eGradient-weighted Class Activation Mapping (Grad-CAM) is a technique used in deep learning to visualize and understand the regions of an input image that a model focuses on when making predictions. It\u0026rsquo;s particularly useful for convolutional neural networks (CNNs) in tasks like image classification. Grad-CAM generates a heatmap that highlights the important regions contributing to the model\u0026rsquo;s decision.\u003c/p\u003e","title":"GradCAM implementation on X-ray classification"},{"content":"ðŸ”— Github Overview This project implements the Loop algorithm for subdivision of the input mesh to smoothen it. The project is completed using the help of half-edge data structures.\nAlgorithm Create the mesh object using the Classes defined in â€˜halfedge_mesh.pyâ€™ and get the list of faces in the mesh object. Looping through faces, calculate the mid points for each edge and update the original vertices. I used dictionary to store the new and updated vertices obtained from each face. Created the list of new faces, where each face gives four faces from the six vertices. The list here stores the indices of the new face vertices. Create the .obj or .off file as output. Instructions to run the code. The package runs without any errors in python = 2 environment. Change the following variables in the main.py:\nmesh â€“ Change the path provided in â€˜HalfedgeMeshâ€™ function to read the input file in â€˜.offâ€™ format. output_file_path â€“ Output path to save the output file in â€˜.objâ€™ or â€˜.offâ€™ format. Obj_output â€“ Boolean parameter to decide the format of output (â€˜Trueâ€™ for .obj and â€˜Falseâ€™ for .off ) The needed functions are defined in the â€˜utils.pyâ€™ file. The comments in the functions explain the input and outputs. For the second iteration, I used the .off file output obtained from the first iteration as an input. The results for first and second iteration (in both .obj and .off format) are placed in â€˜resultsâ€™ folder as a part of submission. ","permalink":"http://localhost:1313/projects/loop-subdivision/","summary":"\u003ch3 id=\"-githubhttpsgithubcomvasavamsiimplementation-of-loop-subdivision-algorithm-using-half-edge-data-structure-in-pythongit\"\u003eðŸ”— \u003ca href=\"https://github.com/vasavamsi/Implementation-of-Loop-Subdivision-Algorithm-using-Half-Edge-Data-Structure-in-Python.git\"\u003eGithub\u003c/a\u003e\u003c/h3\u003e\n\u003ch2 id=\"overview\"\u003eOverview\u003c/h2\u003e\n\u003cp\u003eThis project implements the Loop algorithm for subdivision of the input mesh to smoothen it. The project is completed using the help of \u003ca href=\"https://github.com/carlosrojas/halfedge_mesh\"\u003ehalf-edge data structures\u003c/a\u003e.\u003c/p\u003e\n\u003ch2 id=\"algorithm\"\u003eAlgorithm\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eCreate the mesh object using the Classes defined in â€˜halfedge_mesh.pyâ€™ and get the list of faces in the mesh object.\u003c/li\u003e\n\u003cli\u003eLooping through faces, calculate the mid points for each edge and update the original vertices. I used dictionary to store the new and updated vertices obtained from each face.\u003c/li\u003e\n\u003cli\u003eCreated the list of new faces, where each face gives four faces from the six vertices. The list here stores the indices of the new face vertices.\u003c/li\u003e\n\u003cli\u003eCreate the .obj or .off file as output.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"instructions-to-run-the-code\"\u003eInstructions to run the code.\u003c/h2\u003e\n\u003cp\u003eThe package runs without any errors in python = 2 environment. Change the following variables in the main.py:\u003c/p\u003e","title":"Implementation of Loop Subdivision Algorithm using Half Edge Data Structure"},{"content":"ðŸ”— Github Overview This work is the python implementation of math work explained in the paper Genus Zero Surface Conformal Mapping. I completed this work as a part of Course porject in the course \u0026ldquo;CSE 570 Advanced Computer Graphics I\u0026rdquo;. The project is completed using the help of half-edge data structures.\nAlgorithm Converted the input mesh object (\u0026lsquo;brain.off\u0026rsquo; here) into a gauss map. We then iterate to optimize the tuette energy (algorithm 1) to get the tuette embedding. Using the tuette embedding, we iterate over to optimize the harmonic energy with the energy difference threshold as 1e-5 (can be adjusted). The converged harmonic energy for \u0026lsquo;brain.off\u0026rsquo; comes out to be approximately 25. Create the .obj or .off file for the final conformal mapping. Instructions to run the code. The package runs without any errors in python = 2 environment. Change the following variables in the main.py:\nmesh â€“ Change the path provided in â€˜HalfedgeMeshâ€™ function to read the input file in â€˜.offâ€™ format. file_path â€“ Output path to save the output file in â€˜.objâ€™ or â€˜.offâ€™ format. The helper functions are defined in the â€˜utils.pyâ€™ file. The comments in the functions explain the input and outputs. The obtained result is placed in the results folder. Note: As we have no way to include the texture information, visualization would be hard in the case of python implemantation.\n","permalink":"http://localhost:1313/projects/spherical-map/","summary":"\u003ch3 id=\"-githubhttpsgithubcomvasavamsispherical-conformal-mapping-using-python\"\u003eðŸ”— \u003ca href=\"https://github.com/vasavamsi/Spherical-Conformal-Mapping-using-Python\"\u003eGithub\u003c/a\u003e\u003c/h3\u003e\n\u003ch2 id=\"overview\"\u003eOverview\u003c/h2\u003e\n\u003cp\u003eThis work is the python implementation of math work explained in the paper \u003ca href=\"https://ieeexplore.ieee.org/document/1318721\"\u003eGenus Zero Surface Conformal Mapping\u003c/a\u003e. I completed this work as a part of Course porject in the course \u0026ldquo;CSE 570 Advanced Computer Graphics I\u0026rdquo;. The project is completed using the help of \u003ca href=\"https://github.com/carlosrojas/halfedge_mesh\"\u003ehalf-edge data structures\u003c/a\u003e.\u003c/p\u003e\n\u003ch2 id=\"algorithm\"\u003eAlgorithm\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eConverted the input mesh object (\u0026lsquo;brain.off\u0026rsquo; here) into a gauss map.\u003c/li\u003e\n\u003cli\u003eWe then iterate to optimize the tuette energy (algorithm 1) to get the tuette embedding.\u003c/li\u003e\n\u003cli\u003eUsing the tuette embedding, we iterate over to optimize the harmonic energy with the energy difference threshold as 1e-5 (can be adjusted). The converged harmonic energy for \u0026lsquo;brain.off\u0026rsquo; comes out to be approximately 25.\u003c/li\u003e\n\u003cli\u003eCreate the .obj or .off file for the final conformal mapping.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"instructions-to-run-the-code\"\u003eInstructions to run the code.\u003c/h2\u003e\n\u003cp\u003eThe package runs without any errors in python = 2 environment. Change the following variables in the main.py:\u003c/p\u003e","title":"Spherical Conformal Mapping using Python"},{"content":"ðŸ”— Github Summary With this project, we are aiming to simulate the evacuation of patrons from the Hayden Library in an unfortunate event of fire. Our model will predict the estimated time to evacuate everyone safely with zero casualties. The patronâ€™s safety is assumed once he/she exits the Hayden library through the nearest exit points. Our system (Hayden Library) consists of four levels with a designated layout and seating capacity abiding by fire regulations. We initiate the simulation by triggering the fire alarm. We are aiming to cover scenarios such as uniform/non-uniform distribution of patrons across the facilities along with partial or complete functionality of the library. We will adapt the Parallel DEVS specification for atomic components (Ex. Classroom, Discussion rooms, etc.) for each level which will direct the flow to staircase model and ultimately towards the exit. Our model is customizable for different building layouts and can be highly beneficial for builders and architects to abide by the fire regulations.\nModel Description The classroom (or discussion rooms, common sitting area, etc.) component is a basic parallel atomic component. It is used to model a certain facility at any level in Hayden Library and can be extended to model any other type of facility in the system. This kind of component keeps track of the number of people in that facility. As shown in Figure, with no fire trigger, people can enter or exit the facility, which is controlled by the generator. This count can go from 0 to the maximum capacity of that facility. We define this phase as good in all the components.\nThe population control can be a user defined input, which is coded in the generator model script. Once, the fire alarm is triggered from the generator all components (including staircase and transducer) will change their phases to the fire. During the fire phase, the generator will stop controlling the population and model will try to evacuate the current population. Which is analogous to restricting the entry to library. The Transducer will also start tracking the time from the fire trigger. The same is shown pictorially, in the below figure.\nWe have provided certain limitations on the flow of patrons and stairway capacity to keep the simulation realistic (these restrictions are discussed in Simulation Experiments and Evaluation sections). Once the patrons are evacuated from the components (classrooms, discussion rooms, etc.) the phase will change to safe. We maintain the population count at each level in the staircase model and will signal the transducer as we complete the evacuation of each level. By obtaining these signals, the transducer will note the time taken to evacuate each level, with the given conditions. The staircase model will go into phase safe once the complete building is evacuated. The next section will provide detailed specification tables for each model component. The image below shows the Simview of the model from DEVS Simulator.\nThe demonstration of this model can be found here. The detailed report with experiments and observations can be found here.\n","permalink":"http://localhost:1313/projects/fire-evac/","summary":"\u003ch3 id=\"-githubhttpsgithubcomvasavamsisimulating-fire-evacuation-at-hayden-library-using-devs-simulator\"\u003eðŸ”— \u003ca href=\"https://github.com/vasavamsi/Simulating-Fire-Evacuation-at-Hayden-library-using-DEVS-Simulator\"\u003eGithub\u003c/a\u003e\u003c/h3\u003e\n\u003ch2 id=\"summary\"\u003eSummary\u003c/h2\u003e\n\u003cp\u003eWith this project, we are aiming to simulate the evacuation of patrons from the Hayden Library in an unfortunate event of fire. Our model will predict the estimated time to evacuate everyone safely with zero casualties. The patronâ€™s safety is assumed once he/she exits the Hayden library through the nearest exit points. Our system (Hayden Library) consists of four levels with a designated layout and seating capacity abiding by fire regulations. We initiate the simulation by triggering the fire alarm. We are aiming to cover scenarios such as uniform/non-uniform distribution of patrons across the facilities along with partial or complete functionality of the library. We will adapt the Parallel DEVS specification for atomic components (Ex. Classroom, Discussion rooms, etc.) for each level which will direct the flow to staircase model and ultimately towards the exit. Our model is customizable for different building layouts and can be highly beneficial for builders and architects to abide by the fire regulations.\u003c/p\u003e","title":"Simulating Fire Evacuation at Hayden library using DEVS Simulator"},{"content":"ðŸ”— Github Summary This project is completed as a part of assignment for CSE-561 Modelling, Simulation and Theory of applications. This work leverages the state-of-the-art DEVS simulator to develop the model for Skateboard Generator, Skateboard Transducer and Skateboard models. We also couple these models to create the couple model.\nPre-installations This project utilizes the DEVS Simulator package and needs the same to be installed in your device for running the project. The Source code along with documentation for DEVS Simulator version 6.1.0 can be found here. Some of the prior neccessities to be installed are either of JRE versions from 1.8, 11.02, 11.10 and 15.02 and Maven. It is also recommended to install \u0026lsquo;Eclipse IDE for JAVA developers\u0026rsquo;, you can find the installation details for the same here.\nRunning the simulation After downloading the Simulator packaged in your local device, navigate to the folder \u0026ldquo;DEVS-Suite-Mixerd_Win64_6.1.0\\Models\\Component\\BasicProcessor\u0026rdquo; and place the .java files from this repository here. Follow the steps as below:\nStep 1 - Expand the Package Explorer in the left of the IDE and double click on controller pack (as shown in image below). Now, hower over \u0026lsquo;Run As\u0026rsquo; option and select \u0026lsquo;1 Java Application\u0026rsquo;.\nStep 2 - Select \u0026lsquo;Component Models\u0026rsquo; in the UI.\nStep 3 - Now select the Package as \u0026lsquo;Component.BasicProcessor\u0026rsquo; and Model as any of the desired models provided in this pack. Check the boxes for SimView for Visualization of the model and Tracking to track the simulation.\nStep 4 - Now provide the desired inputs and hit the \u0026lsquo;Step\u0026rsquo; button to run the simulation for one step and so on. You can set n desired steps using \u0026lsquo;Step(n)\u0026rsquo; button.\nNote - The inputs for each model and coupled model can be modified or increased in the code using the function addTestInput.\nImplementation of coupled model:\n","permalink":"http://localhost:1313/projects/skate-board/","summary":"\u003ch3 id=\"-githubhttpsgithubcomvasavamsimodelling-and-simulating-the-skateboard-using-devs-simulator\"\u003eðŸ”— \u003ca href=\"https://github.com/vasavamsi/Modelling-and-Simulating-the-Skateboard-using-DEVS-Simulator\"\u003eGithub\u003c/a\u003e\u003c/h3\u003e\n\u003ch2 id=\"summary\"\u003eSummary\u003c/h2\u003e\n\u003cp\u003eThis project is completed as a part of assignment for CSE-561 Modelling, Simulation and Theory of applications. This work leverages the state-of-the-art DEVS simulator to develop the model for Skateboard Generator, Skateboard Transducer and Skateboard models. We also couple these models to create the couple model.\u003c/p\u003e\n\u003ch2 id=\"pre-installations\"\u003ePre-installations\u003c/h2\u003e\n\u003cp\u003eThis project utilizes the DEVS Simulator package and needs the same to be installed in your device for running the project. The Source code along with documentation for DEVS Simulator version 6.1.0 can be found \u003ca href=\"https://sourceforge.net/projects/devs-suitesim/files/DEVS_Suite_6.1.0/\" style=\"color: orange;\"\u003ehere\u003c/a\u003e. Some of the prior neccessities to be installed are either of JRE versions from 1.8, 11.02, 11.10 and 15.02 and Maven. It is also recommended to install \u0026lsquo;Eclipse IDE for JAVA developers\u0026rsquo;, you can find the installation details for the same \u003ca href=\"https://www.eclipse.org/downloads/packages/installer\"\u003ehere\u003c/a\u003e.\u003c/p\u003e","title":"Modelling and Simulating the Skateboard using DEVS Simulator"},{"content":"ðŸ”— Github Algorithm The Code is initiated with two right most images from the images of the static scene. The Homography is estimated using the RANSAC Algorithm. Now the Origin of the right image is shifted as per Homography calculations and the whole right image is pasted at those co-ordinates in the blank canvas. Now left image of both is pasted in the remaining blank canvas (defined with double the size of images) The remaining blank canvas is removed and only image part is retrieved. The above steps are repeated for the remaining images and the Instead of the right image now whole stitched part in previous steps is shifted in canvas using Homography between corresponding images. Now the remaining blank part in canvas is removed and the saved in the same folder as of images. Instructions to run the code. Create the folder named \u0026lsquo;img_set_1\u0026rsquo; and place the images to be stitched in the folder. We experimented with 8 images.\nStep-1 : The root directory is to be maintained as seen and naming of the images and their folders to be followed in the same fashion.\nStep-2 : The Code is fixed for the set of 8 images, for different no. of images alter the range mentioned in the panaroma_stitching.py (commented in the code)\nStep-3 : The no. of inliers in the ransac.py script can be changed to get the better homography matrix.\nStep-4 : The no. of iterations for the RANSAC Algorithm can also be changed as per user requirement. (Both the above are commented in the code itself)\nStep-5 : To see the intermediate progress, uncomment the part mentioned in panaroma_stitching.py. (the intermediate images will be saved in the same directory in BGR format)\nStep-6 : Currently the code is written to stitch 8 panaromic images, but one can modify as per ones needs.\nDrawbacks Good Horizontal shift is seen but poor vertical shift is observed (can be limited with good dataset with minimum hand glitches while clicking the images).\nIntensity differenced led to many mismatches (Especially in image set 4).\nPixel to Pixel Transformation is leading to very poor results.\nReferences For Homography Estimation: Class Notes\nFor RANSAC Algorithm : Class Notes\n","permalink":"http://localhost:1313/projects/panaroma/","summary":"\u003ch3 id=\"-githubhttpsgithubcomvasavamsipanaroma-stitching-using-python\"\u003eðŸ”— \u003ca href=\"https://github.com/vasavamsi/Panaroma-stitching-using-Python\"\u003eGithub\u003c/a\u003e\u003c/h3\u003e\n\u003ch2 id=\"algorithm\"\u003eAlgorithm\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eThe Code is initiated with two right most images from the images of the static scene.\u003c/li\u003e\n\u003cli\u003eThe Homography is estimated using the RANSAC Algorithm.\u003c/li\u003e\n\u003cli\u003eNow the Origin of the right image is shifted as per Homography calculations and the whole right image is pasted at those co-ordinates in the blank canvas.\u003c/li\u003e\n\u003cli\u003eNow left image of both is pasted in the remaining blank canvas (defined with double the size of images)\u003c/li\u003e\n\u003cli\u003eThe remaining blank canvas is removed and only image part is retrieved.\u003c/li\u003e\n\u003cli\u003eThe above steps are repeated for the remaining images and the Instead of the right image now whole stitched part in previous steps is shifted in canvas using Homography between corresponding images.\u003c/li\u003e\n\u003cli\u003eNow the remaining blank part in canvas is removed and the saved in the same folder as of images.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"instructions-to-run-the-code\"\u003eInstructions to run the code.\u003c/h2\u003e\n\u003cp\u003eCreate the folder named \u0026lsquo;img_set_1\u0026rsquo; and place the images to be stitched in the folder. We experimented with 8 images.\u003c/p\u003e","title":"Panaroma Stitching using Python"},{"content":"Responsibilities Contributed to ongoing research on leveraging advancements in Machine Learning to mimic the functioning of the semi-conductor fabrication industry. Working on the Machine State (Idle/Active) Predictions throughout the Simulation of the Wafer Generation for the given Molecular composition. This work can be interpreted as the binary time-series forecasting given the static variables. This research is sponsored by Intel Labs. ","permalink":"http://localhost:1313/experience/acims/","summary":"\u003ch2 id=\"responsibilities\"\u003eResponsibilities\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eContributed to ongoing research on leveraging advancements in Machine Learning to mimic the functioning of the semi-conductor fabrication industry.\u003c/li\u003e\n\u003cli\u003eWorking on the Machine State (Idle/Active) Predictions throughout the Simulation of the Wafer Generation for the given Molecular composition.\u003c/li\u003e\n\u003cli\u003eThis work can be interpreted as the binary time-series forecasting given the static variables.\u003c/li\u003e\n\u003cli\u003eThis research is sponsored by Intel Labs.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c!-- ![](/experience/16bit/img1.jpeg#center) --\u003e","title":"Graduate Student Researcher"},{"content":"Responsibilities Contributed to ongoing research to aid the medical diagnosis with the help of Image Processing and Deep learning. Solved the Retinal Image Enhancement problem using the improved GAN based approach. Integrated latest development in transformer-based attention mechanism in Unet to solve 3D image segmentation task. Authored multiple manuscripts for submissions at premier conferences such as MICCAI 2024, WACV 2025, and CVPR 2025. My Eye Fundus Image Enhancement technique has been successfully submitted for patent filing on behalf of the Lab. ðŸ”— Lab Website\n","permalink":"http://localhost:1313/experience/gsl/","summary":"\u003ch2 id=\"responsibilities\"\u003eResponsibilities\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eContributed to ongoing research to aid the medical diagnosis with the help of Image Processing and Deep learning.\u003c/li\u003e\n\u003cli\u003eSolved the Retinal Image Enhancement problem using the improved GAN based approach.\u003c/li\u003e\n\u003cli\u003eIntegrated latest development in transformer-based attention mechanism in Unet to solve 3D image segmentation task.\u003c/li\u003e\n\u003cli\u003eAuthored multiple manuscripts for submissions at premier conferences such as MICCAI 2024, WACV 2025, and CVPR 2025.\u003c/li\u003e\n\u003cli\u003eMy Eye Fundus Image Enhancement technique has been successfully submitted for patent filing on behalf of the Lab.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eðŸ”— \u003ca href=\"https://gsl.lab.asu.edu/\"\u003eLab Website\u003c/a\u003e\u003c/p\u003e","title":"Deep Learning Researcher"},{"content":"Responsibilities Conducted performance analysis of web services to optimize efficiency and inform data-driven decisions prior to code deployment. Led a team of 5 in data analysis and project coordination, effectively communicating insights to stakeholders and enhancing project outcomes. Developed a Gatling-based performance testing framework, streamlining data collection processes and saving over 50 hours per project cycle. Achieved a 10% reduction in project costs by leveraging open-source tools instead of commercial load generators for data analysis. Enhanced project management and reporting by utilizing JIRA and Confluence to monitor progress and visualize the product roadmap ","permalink":"http://localhost:1313/experience/tcs/","summary":"\u003ch2 id=\"responsibilities\"\u003eResponsibilities\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eConducted performance analysis of web services to optimize efficiency and inform data-driven decisions prior to code deployment.\u003c/li\u003e\n\u003cli\u003eLed a team of 5 in data analysis and project coordination, effectively communicating insights to stakeholders and enhancing project outcomes.\u003c/li\u003e\n\u003cli\u003eDeveloped a Gatling-based performance testing framework, streamlining data collection processes and saving over 50 hours per project cycle.\u003c/li\u003e\n\u003cli\u003eAchieved a 10% reduction in project costs by leveraging open-source tools instead of commercial load generators for data analysis.\u003c/li\u003e\n\u003cli\u003eEnhanced project management and reporting by utilizing JIRA and Confluence to monitor progress and visualize the product roadmap\u003c/li\u003e\n\u003c/ul\u003e\n\u003c!-- ![](/experience/16bit/img1.jpeg#center) --\u003e","title":"Systems Engineer"},{"content":"Responsibilities Aided research focused towards developing novel techniques for Human face age progression mapping. Leveraged Style transfer GAN to map the Age-groups of 25-60 years. Demonstrated strong communication skills, adeptness in data collection, and advanced analytical skills. Project Abstract Age progression is a process of projection of futuristic aging characteristics onto the subject face image. This kind of task finds applications in cyber-cell forensics, age-invariant facial recognition, and in entertainment sectors up to a certain extent. Most of the previous works tried projecting similar kinds of texture-based artifacts such as artificial wrinkles and dullness of eyes on the test subjects. Even, the analysis to convince the aging effects, as well as identity preservation in the generated images, is not studied in a detailed manner. In this work, we for the first time used the Attention mechanism in combination with weighted contextual loss to accomplish age progression of the human face. We used Attention UNet Generator architecture with the pyramid architecture of discriminator to aid the realness of the generated images. We have also shown the ablation studies for generators with differ- ent blocks in encoder and decoder. By using weighted Contextual loss, we induced the aging artifacts onto the test subject without losing the original identity. We have shown how perceptually close the results are to the real images. Performance evaluation of our work is carried out with the help of external age estimation and identity matching agents for better convincing and reliable quantitative analysis. Our method is robust to occlusion and some regular positions of the faces. This work is done under the guidance and collaboration of the premier R\u0026amp;D organization Center for Development of Advanced Computing (C-DAC), Hyderabad.\nThis work is submitted as the second part of Thesis report at Indian Institute of Technology Gandhinagar. And the Thesis Report can be accessed through the Publications section.\n","permalink":"http://localhost:1313/experience/cdac/","summary":"\u003ch2 id=\"responsibilities\"\u003eResponsibilities\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eAided research focused towards developing novel techniques for Human face age progression mapping.\u003c/li\u003e\n\u003cli\u003eLeveraged Style transfer GAN to map the Age-groups of 25-60 years.\u003c/li\u003e\n\u003cli\u003eDemonstrated strong communication skills, adeptness in data collection, and advanced analytical skills.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"project-abstract\"\u003eProject Abstract\u003c/h1\u003e\n\u003cp\u003eAge progression is a process of projection of futuristic aging characteristics\nonto the subject face image. This kind of task finds applications in cyber-cell\nforensics, age-invariant facial recognition, and in entertainment sectors up to\na certain extent. Most of the previous works tried projecting similar kinds\nof texture-based artifacts such as artificial wrinkles and dullness of eyes on\nthe test subjects. Even, the analysis to convince the aging effects, as well\nas identity preservation in the generated images, is not studied in a detailed\nmanner. In this work, we for the first time used the Attention mechanism in\ncombination with weighted contextual loss to accomplish age progression of\nthe human face. We used Attention UNet Generator architecture with the\npyramid architecture of discriminator to aid the realness of the generated\nimages. We have also shown the ablation studies for generators with differ-\nent blocks in encoder and decoder. By using weighted Contextual loss, we\ninduced the aging artifacts onto the test subject without losing the original\nidentity. We have shown how perceptually close the results are to the real\nimages. Performance evaluation of our work is carried out with the help of\nexternal age estimation and identity matching agents for better convincing\nand reliable quantitative analysis. Our method is robust to occlusion and\nsome regular positions of the faces. This work is done under the guidance\nand collaboration of the premier R\u0026amp;D organization Center for Development\nof Advanced Computing (C-DAC), Hyderabad.\u003c/p\u003e","title":"Computer Vision Intern"},{"content":"Responsibilities Deployed an Object detection algorithm on RaspberryPi to solve a traffic monitoring problem. Improved the detection accuracy to 95.7% while diminishing the detection time by 60%. Designed the pipeline to store the detection details in private cloud. ","permalink":"http://localhost:1313/experience/capgemini/","summary":"\u003ch2 id=\"responsibilities\"\u003eResponsibilities\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eDeployed an Object detection algorithm on RaspberryPi to solve a traffic monitoring problem.\u003c/li\u003e\n\u003cli\u003eImproved the detection accuracy to 95.7% while diminishing the detection time by 60%.\u003c/li\u003e\n\u003cli\u003eDesigned the pipeline to store the detection details in private cloud.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c!-- ![](/experience/16bit/img1.jpeg#center) --\u003e","title":"Winter Intern"},{"content":"Responsibilities Trained to operate the Electrical Support division in the Chemical Industry. Managed team of 10 including machine operators, maintenance staff, and junior engineers. Implemented rigorous Industrial Safety measures, resulting in zero fire or electrical accidents within my team. Extra-curricular Volunteered the social responsibility programs at TATA Chemicals Society for Rural Deveopment (TCSRD) . Led the organizing team to conduct awareness programs on Animal husbandry, efficient Agricultural practices. Enrolled the under privileged public schools in the remote areas to the Mobile Computer Lab. ","permalink":"http://localhost:1313/experience/tata-chemicals/","summary":"\u003ch2 id=\"responsibilities\"\u003eResponsibilities\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eTrained to operate the Electrical Support division in the Chemical Industry.\u003c/li\u003e\n\u003cli\u003eManaged team of 10 including machine operators, maintenance staff, and junior engineers.\u003c/li\u003e\n\u003cli\u003eImplemented rigorous Industrial Safety measures, resulting in zero fire or electrical accidents within my team.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"extra-curricular\"\u003eExtra-curricular\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eVolunteered the social responsibility programs at \u003ca href=\"https://www.tcsrd.org/\" style=\"color: orange;\"\u003e TATA Chemicals Society for Rural Deveopment (TCSRD) \u003c/a\u003e .\u003c/li\u003e\n\u003cli\u003eLed the organizing team to conduct awareness programs on Animal husbandry, efficient Agricultural practices.\u003c/li\u003e\n\u003cli\u003eEnrolled the under privileged public schools in the remote areas to the Mobile Computer Lab.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c!-- ![](/experience/16bit/img1.jpeg#center) --\u003e","title":"Graduate Engineer Trainee"}]